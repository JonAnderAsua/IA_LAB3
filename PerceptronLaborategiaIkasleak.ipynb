{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "PerceptronLaborategiaIkasleak.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lZL61TGIaqe"
      },
      "source": [
        "# Codifica tus própios perceptrones para implementar puertas lógicas\n",
        "En las partes que aparecen así\n",
        "```python\n",
        "pass  # ⬅️✏️\n",
        "```\n",
        "necesitas rellenar código antes de pasar a la siguiente celda.\n",
        "\n",
        "Revisa las transparencias de clase para llevar a cabo estos ejercicios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioC9JWH8Iaqm"
      },
      "source": [
        "### Comenzaremos por implementar una **neurona AND**. Ojo!! No la vamos a entrenar, vamos a asumir que conocemos los pesos (los hemos calculado en clase) \n",
        "\n",
        "Para ello:\n",
        "\n",
        "1) suponemos que el entrenamiento ya está previamente hecho y por lo tanto conocemos los pesos apropiados (consultar las transparencias)\n",
        "\n",
        "2) Nos piden implementar la neurona AND y probar con un item o ejemplo, por ejemplo un vector de input 0,1 que la salida es correcta\n",
        "\n",
        "Recordad que en clase hemos descubierto que los pesos apropiados son:\n",
        "0.66 y 0.8, así que el vector de pesos será [0.66,0.8] y el bias será 1 y el peso para el bias será -0.97"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "PBhEwe_UIaqo"
      },
      "source": [
        "# Definir dos vectores (listas): input my_x, pesos my_w\n",
        "my_x = [0, 1]#input un item\n",
        "my_w = [0.66, 0.80]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AaghI59Iaqq"
      },
      "source": [
        "# Multiplicar dos vectores elemento a elemento\n",
        "def mul(a, b):\n",
        "    \"\"\"\n",
        "    devolver una lista c, de la misma longitud que a y b donde \n",
        "    cada elemento c[i] = a[i] * b[i]\n",
        "    lo podéis hacer con un bucle o con una list comprenhension\n",
        "    \"\"\" \n",
        "    return [x*y for x,y in zip(a,b)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97OR5kWzIaqs",
        "outputId": "9a7e2f77-5506-4ea7-f107-3bba00451650"
      },
      "source": [
        "# Test la función mul() con un item my_x \n",
        "# y los pesos descubiertos en clase my_w, el resultado debería ser \n",
        "# el vector [0.0,0.8]\n",
        "mul(my_x, my_w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.8]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "LtD5zNt4Iaqu"
      },
      "source": [
        "# Define el bias my_bias y el peso descubierto en clase asociado a ese bias\n",
        "# añadiré el bias a el vector de pesos my_w generando un nuevo vector my_wPlusWBias.\n",
        "# Posibles errores: Recordad que en Python las variables con punteros\n",
        "# y el insertar si lo ejecutáis varias veces los valores \n",
        "# se van acumulando dependiendo de cómo hagáis la inserción\n",
        "# my_wPlusWBias debería contener [-0.97, 0.66, 0.8]. Pista para hacer copias de un vector. copiaV=v[:] o copiaV=v.copy()\n",
        "\n",
        "my_bias  = 1\n",
        "my_wbias = -0.97\n",
        "\n",
        "my_wPlusWBias = my_w.copy() #Para copiar la lista\n",
        "my_wPlusWBias.insert(0,my_wbias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZIbULzHIaqw"
      },
      "source": [
        "# Neurona lineal\n",
        "def distanciaDelCoseno(x, weights, bias):\n",
        "    \"\"\"\n",
        "    El producto escalar (producto punto) de dos vectores y la similitud de coseno no son completamente equivalentes \n",
        "    ya que la similitud del coseno solo se preocupa por la diferencia de ángulo, \n",
        "    mientras que el producto de punto se preocupa por el ángulo y la magnitud\n",
        "    Pero en muchas ocasiones se emplean indistintamente\n",
        "    Así pues, esta función devuelve el valor escalar de la neurona, es decir, \n",
        "    el producto escalar entre el vector de entrada añadiendo el bias y el vector de los pesos\n",
        "    recordad que \"sum(list)\" computa la suma de los elementos de una lista\n",
        "    Así pues se comenzará por añadir el bías en la posición 0 del vector de entrada \n",
        "    antes de llevar a cabo el producto escalar para así tener dos vectores de \n",
        "    la misma longitud. Emplea la función mul que ya has programado\n",
        "    \"\"\"\n",
        "    # x = vector de elementos\n",
        "    # weights = vector de pesos\n",
        "    # bias = el valor bias\n",
        "    solucion = 0.0\n",
        "    xCop = x.copy()\n",
        "    xCop.insert(0,bias)\n",
        "    c = mul(xCop,weights)\n",
        "    return sum(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs5ArpOIIaqx",
        "outputId": "d5f0f087-ea63-43da-cfab-f206ee7397e0"
      },
      "source": [
        "# Test distanciaDelCoseno que debería darte -0.16999999999999993 para los datos my_x, my_wPlusWBias, my_bias\n",
        "distanciaDelCoseno(my_x, my_wPlusWBias, my_bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.16999999999999993"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q65J-MEIaqy"
      },
      "source": [
        "# Una neurona perceptron completa, distancia del coseno y activación\n",
        "def neuron(x, weights, bias):\n",
        "    \"\"\"\n",
        "    Devolverá el output de una neurona clásica \n",
        "    (reutilizar la distancia del coseno definida previamente) \n",
        "    y añadir la función de activación (step function): si >=0 entonces 1 sino -1\n",
        "    \"\"\"\n",
        "    output=-1\n",
        "    if distanciaDelCoseno(x,weights,bias) >= 0.0:\n",
        "        output = 1\n",
        "    return output\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PanuVKyvIaq0",
        "outputId": "37782ec8-7e1c-4f0d-a858-089efaa1441e"
      },
      "source": [
        "# Testar la función neuron() para el item my_x y el bias my_b \n",
        "# y el vector de pesos my_wPlusWBias\n",
        "# debería de dar -1 para el input item [0,1] con el bias 1 \n",
        "# y el vector de pesos hayado en clase\n",
        "neuron(my_x, my_wPlusWBias, my_bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "nAkQ2NrQIaq1"
      },
      "source": [
        "# Package AND neuron weights and bias\n",
        "def and_neuron(x):\n",
        "    \"\"\"\n",
        "    Devuelve x1 AND x2 suponiendo que la hemos entrenado\n",
        "    y que en ese entrenamiento hemos aprendido los pesos apropiados \n",
        "    (mirar las transparencias de clase). Así pues inicializaremos \n",
        "    una la variable local and_w con los pesos aprendidos \n",
        "    y a 1 la variable local and_bias \n",
        "    y ejecutaremos la función neurona para el item x\"\"\"\n",
        "    and_w    = [-0.97,0.66, 0.80]#initialization of the weights and_w\n",
        "    and_bias = 1#initialization of the bias and_bias\n",
        "    return neuron(x,and_w,and_bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyAAnx66Iaq2"
      },
      "source": [
        "Ahora nos piden probar la puerta para toda la colección de inputs posibles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e4NiIYWIaq3"
      },
      "source": [
        "# Se definen los items de entrada para testar\n",
        "# las neuronas AND y las posteriores que implementaremos (OR, XOR)\n",
        "# CUIDADO para la neurona NOT hará falta otra colección dado \n",
        "# que los vectores de entrada a la NOT no tienen dos dimensiones sino 1\n",
        "my_x_collection = [\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1],\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arzj0tthIaq3",
        "outputId": "4820de3a-b81d-4131-9a36-dc45c38e386c"
      },
      "source": [
        "# Para los items de entrada my_x_collection la salida debería ser \n",
        "# -1, -1, -1, 1\n",
        "print('Testando el output de la neurona AND')\n",
        "#bucle para ir obteniendo el output de la neurona AND para cada item del input\n",
        "for my_x in my_x_collection:\n",
        "    print(my_x, f'{and_neuron(my_x):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando el output de la neurona AND\n",
            "[0, 0] -1.000\n",
            "[0, 1] -1.000\n",
            "[1, 0] -1.000\n",
            "[1, 1] 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNBCFDN_Iaq4"
      },
      "source": [
        "### Neurona OR\n",
        "\n",
        "Hasta ahora solo habéis tenido que implementar la neurona AND sin tener que entrenarla dado que ya conocíamos los pesos que habíamos aprendido en clase. Es decir, no habéis implementado en Python la fase de entrenamiento de la neurona para determinar los pesos. Ahora se os pide que entrenéis una neurona OR, de forma que realicéis iteraciones sobre los items del input. Para ello los pasos serán:\n",
        "1) Inicializar un vector de pesos de forma random (emplear la librería random **from random import random**)\n",
        "\n",
        "2) Por cada item del input aplicar la neurona y si la predicción realizada por la neurona en base a aplicar  la distancia del coseno y la función de activación no es correcta, entonces ajustar los pesos consecuentemente\n",
        "\n",
        "3) Repetir el paso 2 hasta convergencia (es decir, hasta que todos los items estén correctamente clasificados)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gycgkes4Iaq5",
        "outputId": "0183049e-856f-4004-fa62-2a1e072bc8c1"
      },
      "source": [
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "#inicializaciones\n",
        "print('Entrenando una neurona OR hasta convergencia')\n",
        "notConverge=True\n",
        "seed(1)# Si queremos que el proceso de inicialización random sea replicable\n",
        "orWeights= [random() for i in range(3)]#inicializar de forma random el vector de pesos or_weights\n",
        "print(\"Imprimiendo los pesos random\", orWeights, \"\\n\")\n",
        "orBias   = 1#inicialización del bias a 1\n",
        "orGoldOutputs=[-1,1,1,1]#inicialización del Gold Standard o patrón oro, \n",
        "# es decir, el output que la neurona OR debería aprender a obtener\n",
        "\n",
        "# A inicializar más cosas\n",
        "my_x_collection = [\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1],\n",
        "]\n",
        "claseEstimada = 1\n",
        "\n",
        "#entrenando\n",
        "numeroVuelta = 0\n",
        "\n",
        "while notConverge:\n",
        "    j = 0\n",
        "    \n",
        "    for x in my_x_collection:\n",
        "        valorNeurona = neuron(x, orWeights, orBias)\n",
        "        xCopia = x.copy()\n",
        "        print(\"Se va a probar el siguiente elemento: \" + str(xCopia))\n",
        "        xCopia.insert(0,orBias)\n",
        "        \n",
        "        if valorNeurona != orGoldOutputs[j]: # Si la clase no coincide hay que modificar los pesos\n",
        "            print(\"No es la solución\")\n",
        "            u = 0 # Para ir iterando la lista de pesos\n",
        "            for elemento in xCopia: # Ahora el primer elemento de la lista x es el bias\n",
        "                print(\"Peso viejo: \" + str(orWeights[u]))\n",
        "                orWeights[u] = orWeights[u] - (valorNeurona * elemento)\n",
        "                print(\"Peso nuevo: \" + str(orWeights[u]))\n",
        "                u += 1\n",
        "        j += 1 # Para que coja el siguiente elemento del gold\n",
        "                    \n",
        "    # Una vez comprobados todos los pesos hay que ver si converge\n",
        "    notConverge = False\n",
        "    a = 0\n",
        "    while not notConverge and a < 4:\n",
        "        valorFinalNeurona = neuron(my_x_collection[a],orWeights, orBias)\n",
        "        \n",
        "        print(\"Debería dar el valor: \" + str(orGoldOutputs[a]))\n",
        "        print(\"Da: \" + str(valorFinalNeurona))\n",
        "        \n",
        "        if valorFinalNeurona != orGoldOutputs[a]:\n",
        "            notConverge = True\n",
        "            \n",
        "        a += 1\n",
        "                \n",
        "    print(\"notConverge = \" + str(notConverge))\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando una neurona OR hasta convergencia\n",
            "Imprimiendo los pesos random [0.13436424411240122, 0.8474337369372327, 0.763774618976614] \n",
            "\n",
            "Se va a probar el siguiente elemento: [0, 0]\n",
            "No es la solución\n",
            "Peso viejo: 0.13436424411240122\n",
            "Peso nuevo: -0.8656357558875988\n",
            "Peso viejo: 0.8474337369372327\n",
            "Peso nuevo: 0.8474337369372327\n",
            "Peso viejo: 0.763774618976614\n",
            "Peso nuevo: 0.763774618976614\n",
            "Se va a probar el siguiente elemento: [0, 1]\n",
            "No es la solución\n",
            "Peso viejo: -0.8656357558875988\n",
            "Peso nuevo: 0.13436424411240122\n",
            "Peso viejo: 0.8474337369372327\n",
            "Peso nuevo: 0.8474337369372327\n",
            "Peso viejo: 0.763774618976614\n",
            "Peso nuevo: 1.7637746189766141\n",
            "Se va a probar el siguiente elemento: [1, 0]\n",
            "Se va a probar el siguiente elemento: [1, 1]\n",
            "Debería dar el valor: -1\n",
            "Da: 1\n",
            "notConverge = True\n",
            "Se va a probar el siguiente elemento: [0, 0]\n",
            "No es la solución\n",
            "Peso viejo: 0.13436424411240122\n",
            "Peso nuevo: -0.8656357558875988\n",
            "Peso viejo: 0.8474337369372327\n",
            "Peso nuevo: 0.8474337369372327\n",
            "Peso viejo: 1.7637746189766141\n",
            "Peso nuevo: 1.7637746189766141\n",
            "Se va a probar el siguiente elemento: [0, 1]\n",
            "Se va a probar el siguiente elemento: [1, 0]\n",
            "No es la solución\n",
            "Peso viejo: -0.8656357558875988\n",
            "Peso nuevo: 0.13436424411240122\n",
            "Peso viejo: 0.8474337369372327\n",
            "Peso nuevo: 1.8474337369372327\n",
            "Peso viejo: 1.7637746189766141\n",
            "Peso nuevo: 1.7637746189766141\n",
            "Se va a probar el siguiente elemento: [1, 1]\n",
            "Debería dar el valor: -1\n",
            "Da: 1\n",
            "notConverge = True\n",
            "Se va a probar el siguiente elemento: [0, 0]\n",
            "No es la solución\n",
            "Peso viejo: 0.13436424411240122\n",
            "Peso nuevo: -0.8656357558875988\n",
            "Peso viejo: 1.8474337369372327\n",
            "Peso nuevo: 1.8474337369372327\n",
            "Peso viejo: 1.7637746189766141\n",
            "Peso nuevo: 1.7637746189766141\n",
            "Se va a probar el siguiente elemento: [0, 1]\n",
            "Se va a probar el siguiente elemento: [1, 0]\n",
            "Se va a probar el siguiente elemento: [1, 1]\n",
            "Debería dar el valor: -1\n",
            "Da: -1\n",
            "Debería dar el valor: 1\n",
            "Da: 1\n",
            "Debería dar el valor: 1\n",
            "Da: 1\n",
            "Debería dar el valor: 1\n",
            "Da: 1\n",
            "notConverge = False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jxxdt1DIaq5"
      },
      "source": [
        "### Neurona NOT\n",
        "\n",
        "Ahora implementa el entrenamiento de una neurona NOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pltdvjWIaq7"
      },
      "source": [
        "# Se definen los items de entrada para testar\n",
        "# la neurona NOT. \n",
        "# Recordad que los vectores de entrada a la NOT no tienen dos dimensiones sino 1\n",
        "my_x_collection = [\n",
        "    [0],\n",
        "    [1]\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ3gJgrWIaq7",
        "outputId": "e7a6e5eb-61ab-4155-a17b-ebffe160e34e"
      },
      "source": [
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "\n",
        "#inicializaciones\n",
        "print('Entrenando una neurona NOT hasta convergencia')\n",
        "notConverge=True\n",
        "seed(1)# Si queremos que el proceso de inicialización random sea replicable\n",
        "notWeights= [random() for i in range(3)] #inicializar de forma random el vector de pesos notWeights\n",
        "pass  # ⬅️✏️\n",
        "print(\"Imprimiendo los pesos random\", notWeights, \"\\n\")\n",
        "notBias   = 1#inicialización del bias a 1\n",
        "notGoldOutputs = [-1,1]#inicialización del Gold Standard o patrón oro#inicialización del Gold Standard o patrón oro,notGoldOutput. CUIDADO con el número de valores que ponéis \n",
        "# es decir, el output que la neurona OR debería aprender a obtener\n",
        "\n",
        "#entrenando\n",
        "numeroVuelta = 0\n",
        "while notConverge:\n",
        "    j = 0\n",
        "    \n",
        "    for x in my_x_collection:\n",
        "        valorNeurona = neuron(x, notWeights, notBias)\n",
        "        xCopia = x.copy()\n",
        "        print(\"Se va a probar el siguiente elemento: \" + str(xCopia))\n",
        "        xCopia.insert(0,notBias)\n",
        "        \n",
        "        if valorNeurona != notGoldOutputs[j]: # Si la clase no coincide hay que modificar los pesos\n",
        "            print(\"No es la solución\")\n",
        "            u = 0 # Para ir iterando la lista de pesos\n",
        "            for elemento in xCopia: # Ahora el primer elemento de la lista x es el bias\n",
        "                print(\"Peso viejo: \" + str(notWeights[u]))\n",
        "                notWeights[u] = notWeights[u] - (valorNeurona * elemento)\n",
        "                print(\"Peso nuevo: \" + str(notWeights[u]))\n",
        "                u += 1\n",
        "        j += 1 # Para que coja el siguiente elemento del gold\n",
        "                    \n",
        "    # Una vez comprobados todos los pesos hay que ver si converge\n",
        "    notConverge = False\n",
        "    a = 0\n",
        "    while not notConverge and a < 2:\n",
        "        valorFinalNeurona = neuron(my_x_collection[a],notWeights, notBias)\n",
        "        \n",
        "        print(\"Debería dar el valor: \" + str(notGoldOutputs[a]))\n",
        "        print(\"Da: \" + str(valorFinalNeurona))\n",
        "        \n",
        "        if valorFinalNeurona != notGoldOutputs[a]:\n",
        "            notConverge = True\n",
        "            \n",
        "        a += 1\n",
        "                \n",
        "    print(\"notConverge = \" + str(notConverge))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando una neurona NOT hasta convergencia\n",
            "Imprimiendo los pesos random [0.13436424411240122, 0.8474337369372327, 0.763774618976614] \n",
            "\n",
            "Se va a probar el siguiente elemento: [0]\n",
            "No es la solución\n",
            "Peso viejo: 0.13436424411240122\n",
            "Peso nuevo: -0.8656357558875988\n",
            "Peso viejo: 0.8474337369372327\n",
            "Peso nuevo: 0.8474337369372327\n",
            "Se va a probar el siguiente elemento: [1]\n",
            "No es la solución\n",
            "Peso viejo: -0.8656357558875988\n",
            "Peso nuevo: 0.13436424411240122\n",
            "Peso viejo: 0.8474337369372327\n",
            "Peso nuevo: 1.8474337369372327\n",
            "Debería dar el valor: -1\n",
            "Da: 1\n",
            "notConverge = True\n",
            "Se va a probar el siguiente elemento: [0]\n",
            "No es la solución\n",
            "Peso viejo: 0.13436424411240122\n",
            "Peso nuevo: -0.8656357558875988\n",
            "Peso viejo: 1.8474337369372327\n",
            "Peso nuevo: 1.8474337369372327\n",
            "Se va a probar el siguiente elemento: [1]\n",
            "Debería dar el valor: -1\n",
            "Da: -1\n",
            "Debería dar el valor: 1\n",
            "Da: 1\n",
            "notConverge = False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8ao7eBdIaq7"
      },
      "source": [
        "### Weighted average\n",
        "\n",
        "Ahora implementa el weighted average explicado en las transparencias de clase ¿qué puedes decir acerca de las actualizaciones de los pesos y el número de epochs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZRvLXejIaq8"
      },
      "source": [
        "# Se definen los items de entrada para testar\n",
        "# las neuronas AND y las posteriores que implementaremos (OR, XOR)\n",
        "# CUIDADO para la neurona NOT hará falta otra colección dado \n",
        "# que los vectores de entrada a la NOT no tienen dos dimensiones sino 1\n",
        "my_x_collection = [\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1],\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shjyXbdOIaq8"
      },
      "source": [
        "def matrixAverage(m):\n",
        "    res=list()\n",
        "    acum=list()\n",
        "    if len(m) > 0:\n",
        "        res=[0]*len(m[0])\n",
        "        for v in m:\n",
        "            res = [a+b for a,b in zip (res,v)]\n",
        "        acum=[elem/len(m) for elem in res]\n",
        "    return acum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg4KhsAHIaq9",
        "outputId": "7115dea4-4e05-4d7b-e4dc-77fde3cfa07b"
      },
      "source": [
        "matrix=[[2,3,4],[2,3,4],[2,3,4]]\n",
        "print(matrixAverage(matrix))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.0, 3.0, 4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXz58j-9Iaq-",
        "outputId": "af40b2cb-3ed4-4911-ab36-0d84718046b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "#inicializaciones\n",
        "print('Entrenando una neurona OR hasta convergencia')\n",
        "notConverge=True\n",
        "seed(1)# Si queremos que el proceso de inicialización random sea replicable\n",
        "orWeights= [random() for i in range(3)]#inicializar de forma random el vector de pesos or_weights\n",
        "print(\"Imprimiendo los pesos random\", orWeights, \"\\n\")\n",
        "orBias   = 1#inicialización del bias a 1\n",
        "orGoldOutputs=[-1,1,1,1]#inicialización del Gold Standard o patrón oro, \n",
        "# es decir, el output que la neurona OR debería aprender a obtener\n",
        "weightLength       = len(orWeights) \n",
        "#entrenando\n",
        "numeroVuelta = 0\n",
        "while notConverge:\n",
        "    a=[]\n",
        "    numeroVuelta=numeroVuelta+1\n",
        "    print('La vuelta '+str(numeroVuelta)+' con pesos '+str(orWeights)+' y ')\n",
        "    \n",
        "    for i in range(0,len(my_x_collection)):       \n",
        "        peso=[]\n",
        "        a.append(neuron(my_x_collection[i],orWeights,orBias))\n",
        "        if a[i]!=orGoldOutputs[i]:\n",
        "            oldWeights=orWeights[:]\n",
        "            peso.append(oldWeights)\n",
        "            #recalcular pesos\n",
        "            if a[i]>orGoldOutputs[i]:\n",
        "                for w in range(0,weightLength):\n",
        "                    #promedio ponderado debe ser el promedio del vector de ponderaciones que tenías antes y lo que quedaría.\n",
        "                    orWeights[w]=orGoldOutputs[w]+ orWeights[w]*(-1) #sustracción\n",
        "                    \n",
        "            else:\n",
        "                for w in range(0,weightLength):\n",
        "                    orWeights[w]=orGoldOutputs[w]+ orWeights[w]*(+1) #adición \n",
        "            peso.append(orWeights)\n",
        "            print('- valores actuales: ',orWeights)\n",
        "            print('- valores viejo: ',oldWeights)\n",
        "            orWeights=matrixAverage(peso)\n",
        "                       \n",
        "    if(np.array_equal(a,orGoldOutputs)):\n",
        "        notConverge=False\n",
        "        print('que son óptimos y el valores óptimos '+str(a))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando una neurona OR hasta convergencia\n",
            "Imprimiendo los pesos random [0.13436424411240122, 0.8474337369372327, 0.763774618976614] \n",
            "\n",
            "La vuelta 1 con pesos [0.13436424411240122, 0.8474337369372327, 0.763774618976614] y \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-449575784f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La vuelta '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeroVuelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' con pesos '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' y '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_x_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mpeso\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_x_collection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morWeights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morBias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'my_x_collection' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHlcSSxmIaq-"
      },
      "source": [
        "# Package OR neuron weights and bias\n",
        "def or_neuron(x):\n",
        "    \"\"\"\n",
        "    Devuelve x1 AND x2 suponiendo que la hemos entrenado\n",
        "    y que en ese entrenamiento hemos aprendido los pesos apropiados \n",
        "    (mirar las transparencias de clase). Así pues inicializaremos \n",
        "    una la variable local and_w con los pesos aprendidos \n",
        "    y a 1 la variable local and_bias \n",
        "    y ejecutaremos la función neurona para el item x\"\"\"\n",
        "    or_w    = [-0.3656,0.8474, 0.7637]#initialization of the weights and_w\n",
        "    or_bias = 1#initialization of the bias and_bias\n",
        "    return neuron(x,or_w,or_bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UviGHcQgIaq_",
        "outputId": "cec7c9ce-f9de-441c-d51a-60d2123c67fe"
      },
      "source": [
        "# Para los items de entrada my_x_collection la salida debería ser \n",
        "# -1, -1, -1, 1\n",
        "print('Testando el output de la neurona OR')\n",
        "#bucle para ir obteniendo el output de la neurona AND para cada item del input\n",
        "for my_x in my_x_collection:\n",
        "    print(my_x, f'{or_neuron(my_x):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testando el output de la neurona OR\n",
            "[0, 0] -1.000\n",
            "[0, 1] 1.000\n",
            "[1, 0] 1.000\n",
            "[1, 1] 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViMd2FM_Iaq_"
      },
      "source": [
        "![X-OR](res/xorToLearnWeights.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxHCS9kJIarA",
        "outputId": "73316663-ee46-4a9a-f307-57ebfc14e53b"
      },
      "source": [
        "# Combinando una puerta OR y una AND, y aprendiendo el peso que hay que darle a cada una para obtener un XOR \n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "#inicializaciones\n",
        "print('Entrenando una neurona XOR hasta convergencia')\n",
        "xorConverge=True\n",
        "seed(1)# Si queremos que el proceso de inicialización random sea replicable\n",
        "xorWeights= [random() for i in range(3)]#inicializar de forma random el vector de pesos or_weights\n",
        "print(\"Imprimiendo los pesos random\", xorWeights, \"\\n\")\n",
        "xorBias   = -0.5#inicialización del bias a 0.5\n",
        "xorGoldOutputs=[1,-1,-1,1]#inicialización del Gold Standard o patrón oro, \n",
        "# es decir, el output que la red XOR debería aprender a obtener\n",
        "#entrenando\n",
        "numeroVuelta = 0\n",
        "\n",
        "while xorConverge:\n",
        "    j = 0\n",
        "    \n",
        "    for x in my_x_collection:\n",
        "        solucion = []\n",
        "        solucion.append(and_neuron(x)) #Devuelve la clase del AND\n",
        "        solucion.append(or_neuron(x))  #Devuelve la clase del OR\n",
        "        \n",
        "        valorNeurona = neuron(solucion, xorWeights, xorBias)\n",
        "        xCopia = solucion.copy()\n",
        "        print(\"Se va a probar el siguiente elemento: \" + str(xCopia))\n",
        "        xCopia.insert(0,xorBias)\n",
        "        \n",
        "        if valorNeurona != xorGoldOutputs[j]: # Si la clase no coincide hay que modificar los pesos\n",
        "            print(\"No es la solución\")\n",
        "            u = 0 # Para ir iterando la lista de pesos\n",
        "            for elemento in xCopia: # Ahora el primer elemento de la lista x es el bias\n",
        "                print(\"Peso viejo: \" + str(xorWeights[u]))\n",
        "                xorWeights[u] = xorWeights[u] - (valorNeurona * elemento)\n",
        "                print(\"Peso nuevo: \" + str(xorWeights[u]))\n",
        "                u += 1\n",
        "        j += 1 # Para que coja el siguiente elemento del gold\n",
        "                    \n",
        "    # Una vez comprobados todos los pesos hay que ver si converge\n",
        "    xorConverge = False\n",
        "    a = 0\n",
        "    while not notConverge and a < 2:\n",
        "        valorFinalNeurona = neuron(my_x_collection[a],xorWeights, xorBias)\n",
        "        \n",
        "        print(\"Debería dar el valor: \" + str(xorGoldOutputs[a]))\n",
        "        print(\"Da: \" + str(valorFinalNeurona))\n",
        "        \n",
        "        if valorFinalNeurona != xorGoldOutputs[a]:\n",
        "            xorConverge = True\n",
        "            \n",
        "        a += 1\n",
        "                \n",
        "    print(\"notConverge = \" + str(xorConverge))\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando una neurona XOR hasta convergencia\n",
            "Imprimiendo los pesos random [0.13436424411240122, 0.8474337369372327, 0.763774618976614] \n",
            "\n",
            "Se va a probar el siguiente elemento: [-1, -1]\n",
            "No es la solución\n",
            "Peso viejo: 0.13436424411240122\n",
            "Peso nuevo: -0.3656357558875988\n",
            "Peso viejo: 0.8474337369372327\n",
            "Peso nuevo: -0.15256626306276733\n",
            "Peso viejo: 0.763774618976614\n",
            "Peso nuevo: -0.23622538102338597\n",
            "Se va a probar el siguiente elemento: [-1, 1]\n",
            "No es la solución\n",
            "Peso viejo: -0.3656357558875988\n",
            "Peso nuevo: 0.13436424411240122\n",
            "Peso viejo: -0.15256626306276733\n",
            "Peso nuevo: 0.8474337369372327\n",
            "Peso viejo: -0.23622538102338597\n",
            "Peso nuevo: -1.2362253810233859\n",
            "Se va a probar el siguiente elemento: [-1, 1]\n",
            "Se va a probar el siguiente elemento: [1, 1]\n",
            "No es la solución\n",
            "Peso viejo: 0.13436424411240122\n",
            "Peso nuevo: -0.3656357558875988\n",
            "Peso viejo: 0.8474337369372327\n",
            "Peso nuevo: 1.8474337369372327\n",
            "Peso viejo: -1.2362253810233859\n",
            "Peso nuevo: -0.23622538102338586\n",
            "notConverge = False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3Rd4ZKpIarA"
      },
      "source": [
        "def xor_neuron(x):\n",
        "    \"\"\"\n",
        "    Return x1_ * x2 + x1 * x2_\n",
        "    \"\"\"\n",
        "    xor_w    = [-1.115635755887599, 0.3474337369372327, -0.7362253810233859]\n",
        "    xor_bias = -0.5\n",
        "    new_x=list()\n",
        "    new_x.append(and_neuron(x))\n",
        "    new_x.append(or_neuron(x))\n",
        "    return neuron(new_x, xor_w, xor_bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCKEFCevIarB",
        "outputId": "d1dc8119-50fd-45f8-a494-be60ed445ff3"
      },
      "source": [
        "print('Checking XOR neuron output')\n",
        "for my_x in my_x_collection:\n",
        "    print(my_x, f'{xor_neuron(my_x):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking XOR neuron output\n",
            "[0, 0] 1.000\n",
            "[0, 1] -1.000\n",
            "[1, 0] -1.000\n",
            "[1, 1] 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GblnYlmpIarC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}